turtlebot2: #namespace

    running_step: 0.04 # amount of time the control will be executed
    pos_step: 0.016     # increment in position for each command
    
    #qlearn parameters
    alpha: 1.0
    gamma: 0.7
    epsilon: 0.9
    epsilon_discount: 0.999 # 0.999
    nepisodes: 1000
    nsteps: 200
    number_splits: 50 #set to change the number of state splits for the continuous problem and also the number of env_variable splits

    running_step: 0.06 # Time for each step
    wait_time: 0.1 # Time to wait in the reset phases

    n_actions: 4 # We have 4 actions, Forward, Stop, turn left, turn right

    num_of_sector: 15

    speed_step: 1.0 # Time to wait in the reset phases
    
    obstacle_pose_radius: 4
    
    velocity:
        linear:
            x: 2.0
            y: 0.0
            z: 0.0
        angular:
            x: 0.0 
            y: 0.0
            z: 0.4
    
    robot_movement_area:
        min: {x: -5.0, y: -5.0}
        max: {x: 5.0, y: 5.0}

    goal_point:
        x: 4.5
        y: 0.0
        z: 0.0

    # you should define as many reward as number of sensitivity. These must be a increasing number.
    sensitiviy_distances:
        - 10
        - 8
        - 6
        - 4
        - 2
        - 1
        - 0.3
        - 0.01
        # ...
    
    area_violation_reward: -20
    goal_reached_reward: 100
    collsion_detected_reward: -20
